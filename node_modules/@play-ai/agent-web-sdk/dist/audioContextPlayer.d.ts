import { type MediaPlayerConfig, type MediaPlayer } from './mediaPlayer';
type AudioChunk = {
    sampleRate: number;
    buffer: Float32Array;
};
interface IAudioStream {
    stream: MediaStream;
    streamId: string;
    analyzer: AnalyserNode;
    destNode: MediaStreamAudioDestinationNode;
    close: () => void;
    advance: () => void;
    pause: () => void;
    resume: () => void;
    appendBuffer: (chunk: AudioChunk) => void;
}
/**
 * Manages an AudioContext and allows creation of multiple audio streams
 * that can be played out using <audio> elements. Use of <audio> for
 * playout avoids some of the problems associated with using WebAudio
 * directly, e.g., audio not playing on iOS when the phone is on silent.
 */
export declare class AudioOutputManager extends EventTarget {
    private context?;
    private readonly streams;
    private isWorkletSupported;
    start(): Promise<void>;
    stop(): void;
    createStream(): MediaStream | undefined;
    destroyStream(streamId: string): void;
    advanceStream(streamId: string): void;
    pauseStream(streamId: string): void;
    resumeStream(streamId: string): void;
    getAudioStream(streamId: string): IAudioStream;
    getAnalyzer(streamId: string): AnalyserNode;
    getMediaStreamDestNode(streamId: string): MediaStreamAudioDestinationNode;
    appendBuffer(streamId: string, chunk: AudioChunk): void;
    private handleStreamStateChange;
}
export declare class Mp3Decoder {
    private onData;
    private onError;
    private readonly decoder;
    private readonly decoderReadyPromise;
    constructor(onData: (audioChunk: AudioChunk) => void, onError: (error: Error) => void);
    addData(encodedBuffer: ArrayBuffer): Promise<void>;
    reset(): Promise<void>;
    free(): void;
}
/**
 * Defines a text-to-speech service that requests individual audio utterances
 * from a server and plays them out using Web Audio and <audio> elements.
 * This approach reduces latency by allowing the audio to be streamed as it is
 * generated, rather than waiting for the entire audio file to be generated. It also
 * allows text to be fed to the service in a stream rather than all at once.
 */
export declare class AudioContextPlayer implements MediaPlayer {
    private shouldPlay;
    private streamId;
    private readonly audio;
    private outputManager;
    private mp3Decoder;
    private audioFormat;
    private hasBufferedData;
    private lastPlaybackTime;
    private silenceDetected;
    private isWaiting;
    private isPlaying;
    private lastStateChange;
    private pendingPlay;
    private onPlay;
    private onStop;
    private onEmpty;
    constructor(config: MediaPlayerConfig);
    init({ onPlay, onStop, onEmpty }: {
        onPlay: () => void;
        onStop: () => void;
        onEmpty: () => void;
    }): Promise<void>;
    appendAudioChunk: (audioData: Uint8Array) => void;
    advance: () => void;
    pause(): void;
    getIsPaused(): boolean;
    resume(): void;
    private systemPlay;
    private elOnWaiting;
    private elOnPlay;
    private elOnPlaying;
    private elOnCanPlay;
    private elOnPause;
    private elOnEnded;
    private onBuffersComplete;
    clear(): void;
    protected appendChunk(chunk: AudioChunk): void;
    get analyserNode(): AnalyserNode;
    get mediaStreamDestNode(): MediaStreamAudioDestinationNode;
    startMicRecording(): Promise<boolean>;
}
export {};
